<!DOCTYPE HTML>
<!--
	Yao Fu
        Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Yao Fu</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/YaoFu.jpg" alt="" /></a>
					<h1>I am <strong>Clark(Yao) Fu</strong>, a  PhD student of the<br />
					<a href="https://engineering.case.edu/computer-and-data-sciences"> Computer and Data Sciences Department</a>
					at <a href="https://case.edu/">Case Western Reserve University</a>. </h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<div style="display: flex" bordercolor="#333333">
        <!-- <th width="19%" height="30" scope="col"><a href="https://yin-yu.github.io/#biography" class="STYLE212">Biography</a></th> <div align="center"> -->
        <div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#one" 
																						    class="STYLE212">Introduction</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
        <div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#two">Education</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
        <div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#three">Publications</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
        <div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#four">Skills</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
        <div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#five">Experience</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#six">Courses</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#seven">Honors</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#eight">Hobby</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a>|</a></b></span></div></div>
	<div width="15%" scope="col" style="padding: 2px"><div><span class="STYLE217" style="font-size: 1.2rem"><b style="font-family:'Times New Roman'; mso-bidi-font-weight: normal"><a href="https://clarkfu007.github.io/#nine">Contact</a></b></span></div></div>
      </div>

				<!-- One -->
					<section id="one">
						<header class="major">
							<h2 style="color: purple;">Introduction üìñ</h2>
						</header>
						<p> I'm a PhD candidate in the Computer and Data Sciences (CDS) department at 
							Case Western Reserve University (CWRU) 
							advised by <a href="https://engineering.case.edu/panli"> 
							Prof. Li</a>. I am also closely working with <a href="https://yin-yu.github.io/"> 
							Prof. Yin</a> and <a href="https://ahxt.github.io/"> 
							Prof. Han</a>. Currently I focus on knowledge distillation, pruning and quantization,
							self-training with direct preference optimization, truthfulness analysis, 
							knowledge probing, chain-of-thought prompting in large language models 
							(e.g., LLaMA, Mistral, and Qwen model families); and security and privacy issues in federated learning. 
							Recently, I have been actively writing papers for prestigious machine learning conferences 
							such as NeurIPS, ICLR, ICML, ACL, EMNLP, NAACL, and COLM. <br />
						<br />
							Before reaching CWRU, I obtained my master degree of Electrical and Computer Engineering 
							(ECE, Machine Learning and Data Science track) 
							from University of Southern California (USC), where I was a research member of 
							<a href="https://sites.usc.edu/dslab/">Data Science Lab</a> supervised by 
							<a href="https://sanmukh.github.io/"> Prof. Kuppannagari</a>, <a href="https://hal.usc.edu/">Hardware Accelerated Learning (HAL) Research Group</a> 
							supervised by <a href="https://ksouvik52.github.io/"> Dr. Kundu</a>, and <a href="https://nicr.ini.usc.edu/"> Neuro Image Computing Research (NICR) Group</a>
							supervised by <a href="https://scholar.google.com/citations?user=sm2Y-6sAAAAJ&hl=en&oi=ao"> 
							Prof. Shi</a>. During my academical life at USC, I was devoted to using PyTorch to focus on 
							cutting-edge topics of applied Machine Learning such as missing smart-meter data imputation, privacy study 
							in knowledge distillation within computer vision, and filtering streamlines from diffusion MRI tractography.
						<br />
						<br />
							What's more, I received my Bachelor's degree on Automation from Nanjing University of 
							Science and Technology. I once spent a fall semester as a transfer graduate student at the 
							ECE Department of North Carolina State University (NCSU), where I attained familiarity 
							with probability and improved my coding ability. My high school is Chengdu NO.7 
							High School(ÊàêÈÉΩÂ∏ÇÁ¨¨‰∏É‰∏≠Â≠¶).
						</p>
					</section>

				<!-- Two -->
				<section id="two">
					<h2 style="color: purple;">Education üéì</h2>
					<p> ‚Ä¢ Case Western Reserve University (CWRU), Cleveland, OH &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp; Aug. 2022 ‚Äì May 2027 (Expected) <br />
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Doctor of Philosophy in Computer and Data Sciences, total GPA 3.67/4.00</strong>  <br />
						‚Ä¢ University of Southern California (USC), Los Angeles, CA &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;Jan. 2020 ‚Äì Dec. 2021 (Graduated) <br />
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Master of Science in Electrical and Computer Engineering, totel GPA 4.00/4.00</strong>  <br />
						‚Ä¢ North Carolina State University (NCSU), Raleigh, NC &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aug. 2019 - Dec. 2019 (Transfer) <br />
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Master of Science in Electrical and Computer Engineering, total GPA 4.00/4.00</strong>  <br />   
						‚Ä¢ Nanjing University of Science and Technology (NJUST), Nanjing, China &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;Sep. 2015 - Jun. 2019 (Graduated) <br />
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Bachelor of Engineering in Automation, total GPA 3.39/4.00 (43/175)</strong>
						 
					</p>
				</section>

				<!-- Three -->
				<section id="three">
					<h2 style="color: purple;">Publications üìë</h2>
					<h2 style="color: green;">Journal</h2>
					<p> [1] Souvik Kundu, <strong>Yao Fu</strong>, Bill Ye, Peter A. Beerel, and Massoud Pedram. <em><span style="color: rgb(0, 101, 232);">
						Towards Adversary Aware Non-Iterative Model Pruning Through Dynamic Network Rewiring of DNNs</span></em>. 
						Association for Computing Machinery (<strong><span style="color: orange;">ACM 2021</span></strong>). <br />
						
					</p>
					<h2 style="color: green;">Conference</h2>
					<p> [1] <strong>Yao Fu</strong>, Runchao Li, Xianxuan Long, Haotian Yu, Xiaotian Han, Yu Yin, and Pan Li. 
						<em><span style="color: rgb(0, 101, 232);">Pruning Weights but Not Truth: Safeguarding Truthfulness While Pruning LLMs</span></em>. 
						Empirical Methods in Natural Language Processing (<strong><span style="color: orange;">EMNLP 2025, Findings, Poster</span></strong>). 
						<a href="https://arxiv.org/abs/2509.00096" 
							target="_blank" 
							class="icon solid fa-file-pdf" 
							style="margin-right:1px; font-size:1.2rem; color:#d9534f;">
							<span class="label">PDF</span>
						</a>
						<a href="https://github.com/ClarkFu007/TPLO" 
							target="_blank" 
							class="icon brands fa-github" 
							style="font-size:1.2rem; color:#333;">
							<span class="label">Code</span>
						</a> <br />
					    [2] <strong>Yao Fu</strong>, Xianxuan Long, Runchao Li, Haotian Yu, Mu Sheng, Xiaotian Han, Yu Yin, and Pan Li. 
						<em><span style="color: rgb(0, 101, 232);">Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs</span></em>. 
						Empirical Methods in Natural Language Processing (<strong><span style="color: orange;">EMNLP 2025, Main Conference, Poster</span></strong>). 
						<a href="https://arxiv.org/abs/2508.19432" 
							target="_blank" 
							class="icon solid fa-file-pdf" 
							style="margin-right:1px; font-size:1.2rem; color:#d9534f;">
							<span class="label">PDF</span>
						</a>
						<a href="https://github.com/ClarkFu007/TruthfulnessEval/" 
							target="_blank" 
							class="icon brands fa-github" 
							style="font-size:1.2rem; color:#333;">
							<span class="label">Code</span>
						</a> <br />
					    [3] Xianxuan Long, <strong>Yao Fu</strong>, Runchao Li, Mu Sheng, Haotian Yu, Xiaotian Han, and Pan Li. 
						<em><span style="color: rgb(0, 101, 232);">When Truthful Representations Flip Under Deceptive Instructions?</span></em> 
						Empirical Methods in Natural Language Processing (<strong><span style="color: orange;">EMNLP 2025, Main Conference, Oral</span></strong>).
						<a href="https://arxiv.org/abs/2507.22149" 
							target="_blank" 
							class="icon solid fa-file-pdf" 
							style="margin-right:1px; font-size:1.2rem; color:#d9534f;">
							<span class="label">PDF</span>
						</a>
						<a href="https://github.com/ivyllll/truthful-representation-flip" 
							target="_blank" 
							class="icon brands fa-github" 
							style="font-size:1.2rem; color:#333;">
							<span class="label">Code</span>
						</a> 
						<br />
					    [4] Runchao Li, <strong>Yao Fu</strong>, Mu Sheng, Xianxuan Long, Haotian Yu, and Pan Li. 
						<em><span style="color: rgb(0, 101, 232);">FAEDKV: Infinite-Window Fourier Transform for Unbiased KV Cache Compression</span></em>.
						Empirical Methods in Natural Language Processing (<strong><span style="color: orange;">EMNLP 2025, Findings, Poster</span></strong>).
						<a href="https://arxiv.org/abs/2507.20030" 
							target="_blank" 
							class="icon solid fa-file-pdf" 
							style="margin-right:1px; font-size:1.2rem; color:#d9534f;">
							<span class="label">PDF</span>
						</a>
						<br />
					    [5] Souvik Kundu, Qirui Sun, <strong>Yao Fu</strong>, Massoud Pedram, and Peter A. Beerel. 
						<em><span style="color: rgb(0, 101, 232);">Analyzing the Confidentiality of Undistillable Teachers in Knowledge Distillation</span></em>. 
						Advances in Neural Information Processing Systems (<strong><span style="color: orange;">NeurIPS 2021</span></strong>).  
						<a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/4ca82782c5372a547c104929f03fe7a9-Paper.pdf" 
							target="_blank" 
							class="icon solid fa-file-pdf" 
							style="margin-right:1px; font-size:1.2rem; color:#d9534f;">
							<span class="label">PDF</span>
						</a>
						<a href="https://github.com/ksouvik52/Skeptical2021" 
							target="_blank" 
							class="icon brands fa-github" 
							style="font-size:1.2rem; color:#333;">
							<span class="label">Code</span>
						</a> <br />
					    [6] Sanmukh R. Kuppannagari, <strong>Yao Fu</strong>, Chung Ming Cheung, and Viktor K. Prasanna. 
						<em><span style="color: rgb(0, 101, 232);">Spatio-Temporal Missing Data Imputation for Smart Power Grids</span></em>. 3rd International 
						Workshop on Applied Machine Learning for Intelligent Energy Systems (<strong><span style="color: orange;">AMLIES 2021</span></strong>). <br />
					    [7] Yuan Li, Xinyu Nie, <strong>Yao Fu</strong>, and Yonggang Shi. 
						<em><span style="color: rgb(0, 101, 232);">FASSt: Filtering via Symmetric Autoencoder for Spherical Superficial White Matter Tractography</span></em>. 
						In International Workshop on Computational Diffusion MRI, pp. 129-139. Cham: Springer Nature Switzerland, 2023.
					</p>
				</section>

				<!-- Four -->
				<section id="four">
					<h2 style="color: purple;">Skills üõ†Ô∏è</h2>
					<p> ‚Ä¢ <strong>Languages:</strong> Python, Java, C/C++, SQL, MATLAB, R <br />
						‚Ä¢ <strong>Developer Tools:</strong> PyCharm, VS Code, CLion, Git, IntelliJ, Eclipse <br />
						‚Ä¢ <strong>Libraries:</strong> PyTorch, JAX, Hugging Face, DeepSpeed, Triton, 
						LlamaIndex, LangChain, LangGraph, vLLM,
						Scikit-Learn, NumPy, Pandas, TensorFlow, Keras, OpenCV, NLTK
					</p>
				</section>

				<!-- Five -->
				<section id="five">
					<h2 style="color: purple;">Experience üí°</h2>
					<strong>‚Ä¢ Research Intern (Futurewei Technologies, Inc.)</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Jun. 2025 ‚Äì Aug. 2025</strong> <br />
						<strong>üí° <span style="color: orange;">Project:</span></strong> Data platform and Large Language Models (LLM) related enterprise system solutions, covering areas such as Vector Database, 
					Knowledge Graph (KG), GraphRAG (a symbolic RAG method that uses multi-hop subgraph retrieval from a KG to ground LLM outputs), Model Context Protocol (MCP) 
					and Mem0 (a novel memory architecture that dynamically captures, organizes, and retrieves salient information from ongoing conversations). <br />
                                        
					- Defined ‚ÄúSufficient Context‚Äù, an explicit criterion to judge if retrieved document chunks sufficiently support answering a given query. <br />

                                        - Proposed a novel alignment method that helps RAG models accurately recognize their knowledge boundaries and guilds them to explicitly 
					abstain (i.e., say ‚ÄúI don‚Äôt know‚Äù) when neither retrieved context nor internal knowledge is sufficient, significantly enhancing honesty 
					and reducing hallucinations. <br />

                                        - Introduced Trust-Score, a comprehensive metric to measure LLM‚Äôs groundedness under RAG, where model responses should be 
					derived from retrieved documents (external memory) rather than the parametric knowledge (knowledge stored in 
					model parameters). <br /> <br />
					
					<p> <strong>‚Ä¢ PhD Research Assistant (CDS Department at CWRU)</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;<strong>Aug. 2022 ‚Äì May 2027 (Expected)</strong> <br />
						<strong>üí° <span style="color: orange;">Project 1:</span></strong> Explored knowledge distillation, self-training with Direct Preference Optimization, Mixture of Experts, 
						self-correction, parameter-efficient fine-tuning (LoRA, Quantization-aware LoRA, LoRAPrune) for large language models 
						(LLaMA2-7/13B and Mistral-7B) on mathematical reasoning capabilities measured by GSM8K. <br />
						<strong>üí° <span style="color: orange;">Project 2:</span></strong> Implemented Training of Truth and Polarity Direction and Logistic Regression to 
						probe LLaMA3.1-8B-Instruct's internal states to implement lie detection, measured by performance on true and 
						false context statements and TruthfulQA. <br />
						<strong>üí° <span style="color: orange;">Project 3:</span></strong> Implemented Activation-aware Weight Quantization (AWQ) and Pruning by Weights and Activations (Wanda) to 
						compress LLaMA2-7B/13B and Mistral-7B. Evaluated compression performance by perplexity on wikitext-2, 
						zero-shot task classification on commonsense reasoning datasets, and model size reductions. <br />
						<strong>üí° <span style="color: orange;">Project 4:</span></strong> Realized FasterVLM, a training-free method to prune visual tokens via attention weights from the [CLS] token 
						within the image encoder, to accelerate vision-language model (LLaVA1.5-7B/13B) inference, achieving up to 95% token 
						reduction while maintaining 90\% performance across multi-modal benchmarks (e.g., VQAv2 and GQA). <br />
						<strong>üí° <span style="color: orange;">Project 5:</span></strong> Deployed a quantized LLaMA2-7B to run a chatbot on 14-inch MacBook Pro and observed the end-to-end latency
						improvement achieved by different optimization techniques (loop unrolling, multithreading, and SIMD
						programming) for the linear kernel. <br />
						<strong>üí° <span style="color: orange;">Project 6:</span></strong> Realized one-shot federated learning via data distillation or data-free knowledge distillation techniques to reduce communication costs. <br />
						<strong>üí° <span style="color: orange;">Project 7:</span></strong> Used PyTorch to implement both unconditional and conditional Denoising Diffusion Probabilistic Models (DDPM) based on CIFAR-10, 
						where the conditional one includes Classifier-Free-Guidance (CFG) and Exponential-Moving-Average (EMA).  <br /> <br />
                  
						<strong>‚Ä¢ Master Research Assistant (Keck School of Medicine at USC)</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Sep. 2021 ‚Äì Jun. 2022</strong> <br />
						<strong>üí° <span style="color: orange;">Project:</span></strong> Filtered brain streamlines from diffusion MRI tractography via deep learning models (U-Net and Autoencoders). <br /> <br />
					
						<strong>‚Ä¢ Master Research Assistant (HAL Research Group at USC)</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Jan. 2021 ‚Äì Dec. 2021</strong> <br />
						<strong>üí° <span style="color: orange;">Project:</span></strong> Explored the deep learning research on Robustness and Privacy associated with model compression such as
						pruning, quantization, and knowledge distillation for image classification and object detection. <br /> <br />

						<strong>‚Ä¢ Master Research Assistant (Data Science Lab at USC)</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<strong>May 2020 ‚Äì Sep. 2021</strong> <br />
						<strong>üí° <span style="color: orange;">Project:</span></strong> Implemented missing data imputation using denoising Autoencoders and spatio-temporal graph neural networks. <br />
												 
					</p>
				</section>


				<!-- Six -->
				<section id="six">
					<h2 style="color: purple;">Courses üìö</h2>
					<h2 style="color: green;">Case Western Reserve University (CWRU)</h2>
					<p> ‚Ä¢ CSDS-410: Analysis of Algorithms. (2022 Fall, my grade: A) <br />
					    ‚Ä¢ CSDS-425: Computer Networks. (2022 Fall, my grade: C) <br />
					    ‚Ä¢ CSDS-433: Database Systems. (2023 Spring, my grade: A) <br />
					    ‚Ä¢ CSDS-456: Data Privacy. (2023 Spring, my grade: A) <br />
					    ‚Ä¢ CSDS-497: Natural Language Processing. (2022 Fall, my grade: A) <br />
					    ‚Ä¢ CSDS-600: Special Topics (Deep Generative Models). (2023 Fall, my grade: A) <br />
					    ‚Ä¢ CSDS-600: Special Topics (Large Language Models). (2024 Fall, Audit) <br />
					    ‚Ä¢ CSDS-233: Introduction to Data Structures. (2022 Fall and 2023 Spring, Teaching Assistant) <br />
					    ‚Ä¢ CSDS-438: High Performance Data and Computing. (2023 Fall, Teaching Assistant) <br />
					</p>
					<h2 style="color: green;">University of Southern California (USC)</h2>
					<p> ‚Ä¢ EE-510: Linear Algebra for Engineering. (2020 Sprinig, my grade: A) <br />
						‚Ä¢ EE-546: Mathematics of High-Dimensional Data. (2020 Fall, my grade: A) <br />
						‚Ä¢ EE-559: Machine Learning 1: Supervised Methods - basics of Supervised classification and regression. (2021 Sprinig, my grade: A) <br />
						‚Ä¢ EE-569: Introduction to Digital Image Processing. (2020 Sprinig, my grade: A) <br />
						‚Ä¢ EE-660: Machine Learning 2: Mathematical Foundations and Methods - Semi-supervised, and unsupervised machine learning; domain adaptation and transfer learning; 
						and techniques for interpretable machine learning. Feasibility of learning, model complexity, and performance (error) on unseen data. (2021 Fall, my grade: A) <br />
						‚Ä¢ CSCI-455x: Introduction to Programming System Design - basics of Java, C++ and Unix/Linux. (2021 Sprinig, my grade: A) <br />
						‚Ä¢ CSCI-570: Analysis of Algorithms. (2020 Fall, my grade: A) <br />
					</p>
					<h2 style="color: green;">North Carolina State University (NCSU)</h2>
					<p> ‚Ä¢ ECE-513: Digital Signal Processing. (2019 Fall, my grade: A) <br />
						‚Ä¢ ECE-514: Random Process - basics of probability, statistics, and random process. (2019 Fall, my grade: A) <br />
						‚Ä¢ ECE-558: Digital Imaging Syetems - basics of digital image processing and computer vision. (2019 Fall, my grade: A) <br />
					</p>
					<h2 style="color: green;">Online Courses </h2>
					<p> ‚Ä¢ Stanford-CS221: Artificial Intelligence. <br />
						‚Ä¢ Stanford-CS224n: Natural Language Processing with Deep Learning. <br />
						‚Ä¢ Stanford-CS224u: Natural Language Understanding. <br />
						‚Ä¢ Stanford-CS224w: Machine Learning with Graphs. <br />
						‚Ä¢ Stanford-CS229: Machine Learning. <br />
						‚Ä¢ Stanford-CS231n: Deep Learning for Computer Vision. <br />
						‚Ä¢ Stanford-CS330: Deep Multi-Task & Meta Learning. <br />
						‚Ä¢ MIT-6.0001: Introduction to Computer Science and Programming in Python. <br />
						‚Ä¢ MIT-6.0002: Introduction to Computational Thinking and Data Science. <br />
						‚Ä¢ MIT-6.0006: Introduction to Algorithms. <br />
						‚Ä¢ MIT-6.5940: TinyML and Efficient Deep Learning Computing. <br />
						‚Ä¢ MIT-18.650: Statistics for Applications. <br />
					</p>
				</section>

				<!-- Seven -->
				<section id="seven">
					<h2 style="color: purple;">Honors üèÜ</h2>
					<p> ‚Ä¢ MS Honors Program: USC Ming Hsieh Department of Electrical Engineering, Fall 2021.
					</p>
				</section>

				<!-- Eight -->
				<section id="eight">
					<h2 style="color: purple;">Hobby üíú</h2>
					<p> ‚Ä¢ <strong>ü§ì Reading:</strong> I am particular interested in reading novels from Keigo Higashino (‰∏úÈáéÂú≠Âêæ) such as ‚ÄúJourney Under the Midnight Sun (ÁôΩÂ§úË°å)‚Äù 
						and ‚ÄúThe Miracles of the Namiya General Store (Ëß£ÂøßÊùÇË¥ßÂ∫ó)‚Äù, and history books such as History of China, History of the United States, 
						World War I and II, History of Europe, and so on. Feel free to chat with me! <br />
					    ‚Ä¢ <strong>üí™ Exercising:</strong> I often run 4.5 miles or go to the gym for anaerobic exercises to relax. <br />
					    ‚Ä¢ <strong>üé¨ Watching:</strong> I am fond of watching Korean Dramas (All of Us are Dead, Squid Game, inter alia) 
						and American Dramas (Mayor of Kingstown, Special Ops: Lioness, House of the Dragon, 
						The Last of Us, The Walking Dead, inter alia). <br />
					    ‚Ä¢ <strong>üéÆ Playing Video Games:</strong> League of Legends, PUBG: Battlegrounds, Call of Duty, World War Z: Aftermath, and so on.				
					</p>
				</section>


				<!-- Nine -->
				<section id="nine">
					<h2 style="color: purple;">Contact üì¨</h2>
					<p> ‚Ä¢ Email address: yxf484@case.edu <br />
						‚Ä¢ <a href="https://scholar.google.com/citations?user=oDTcsjQAAAAJ&hl=en"> Google Scholar</a> <br />
						‚Ä¢ <a href="https://www.linkedin.com/in/yao-fu-403680191/"> LinkedIn</a> <br />
						‚Ä¢ <a href="https://github.com/ClarkFu007"> Github</a> <br />
						‚Ä¢ <a href="https://twitter.com/ClarkFu17"> Twitter</a> <br />
					</p>
				</section>
			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://scholar.google.com/citations?user=oDTcsjQAAAAJ&hl=en" class="icon brands fa-google"><span class="label">Google Scholar</span></a></li>
						<li><a href="https://www.linkedin.com/in/yao-fu-403680191/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/ClarkFu007" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="https://twitter.com/ClarkFu17" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>







